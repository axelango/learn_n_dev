{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "save_load_model_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsBzqA1RxJ0cRX3uoUWaNK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgamel/learn_n_dev/blob/python_machine_learning/save_load_model_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to Save and Load Your Keras Deep Learning Model"
      ],
      "metadata": {
        "id": "tjnUttB8nHYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given that deep learning models can take hours, days and even weeks to train, it is important to know how to save and load them from disk."
      ],
      "metadata": {
        "id": "PVft1VnqnLYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this script:\n",
        "\n",
        "* How to save model weights and model architecture in separate files.\n",
        "* How to save model architecture in JSON format.\n",
        "* How to save model weights and architecture into a single file for later use."
      ],
      "metadata": {
        "id": "CGqSsDgknN2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overview:**\n",
        "\n",
        "Keras separates the concerns of saving your model architecture and saving your model weights.\n",
        "\n",
        "Model weights are saved to HDF5 format. This is a grid format that is ideal for storing multi-dimensional arrays of numbers.\n",
        "\n",
        "The model structure can be described and saved using two different formats: JSON and YAML.\n",
        "\n",
        "In this post we are going to look at one example of saving and loading your model to file:\n",
        "\n",
        "* Save Model to JSON.\n",
        "\n",
        "\n",
        "The example will also demonstrate saving and loading your model weights to HDF5 formatted files."
      ],
      "metadata": {
        "id": "BOadq_YjnkLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Your Neural Network Model to JSON"
      ],
      "metadata": {
        "id": "HOWJRZ7PnnlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "JSON is a simple file format for describing data hierarchically.\n",
        "\n",
        "Keras provides the ability to describe any model using JSON format with a to_json() function. This can be saved to file and later loaded via the model_from_json() function that will create a new model from the JSON specification.\n",
        "\n",
        "The weights are saved directly from the model using the save_weights() function and later loaded using the symmetrical load_weights() function.\n",
        "\n",
        "The example below trains and evaluates a simple model on the Pima Indians dataset. The model is then converted to JSON format and written to model.json in the local directory. The network weights are written to model.h5 in the local directory.\n",
        "\n",
        "The model and weight data is loaded from the saved files and a new model is created. It is important to compile the loaded model before it is used. This is so that predictions made using the model can use the appropriate efficient computation from the Keras backend.\n",
        "\n",
        "The model is evaluated in the same way printing the same evaluation score."
      ],
      "metadata": {
        "id": "WRVR4M9Enqu1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHMGB0q_kIZB",
        "outputId": "b10b8bef-c538-4871-ac60-edc100807d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"/content/gdrive/My Drive/input_examples/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/gdrive/My Drive/models/model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/gdrive/My Drive/models/model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "# later...\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('/content/gdrive/My Drive/models/model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/gdrive/My Drive/models/model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOeLsFbZlaBJ",
        "outputId": "113b0e94-d789-45d6-b02f-9358771e5242"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 76.30%\n",
            "Saved model to disk\n",
            "Loaded model from disk\n",
            "accuracy: 76.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running this example provides the output below.\n",
        "\n",
        "```\n",
        "acc: 78.78%\n",
        "Saved model to disk\n",
        "Loaded model from disk\n",
        "acc: 78.78%\n",
        "```\n",
        "\n",
        "The JSON format of the model looks like the following:\n",
        "\n",
        "```\n",
        "{  \n",
        "   \"class_name\":\"Sequential\",\n",
        "   \"config\":{  \n",
        "      \"name\":\"sequential_1\",\n",
        "      \"layers\":[  \n",
        "         {  \n",
        "            \"class_name\":\"Dense\",\n",
        "            \"config\":{  \n",
        "               \"name\":\"dense_1\",\n",
        "               \"trainable\":true,\n",
        "               \"batch_input_shape\":[  \n",
        "                  null,\n",
        "                  8\n",
        "               ],\n",
        "               \"dtype\":\"float32\",\n",
        "               \"units\":12,\n",
        "               \"activation\":\"relu\",\n",
        "               \"use_bias\":true,\n",
        "               \"kernel_initializer\":{  \n",
        "                  \"class_name\":\"VarianceScaling\",\n",
        "                  \"config\":{  \n",
        "                     \"scale\":1.0,\n",
        "                     \"mode\":\"fan_avg\",\n",
        "                     \"distribution\":\"uniform\",\n",
        "                     \"seed\":null\n",
        "                  }\n",
        "               },\n",
        "               \"bias_initializer\":{  \n",
        "                  \"class_name\":\"Zeros\",\n",
        "                  \"config\":{  \n",
        "\n",
        "                  }\n",
        "               },\n",
        "               \"kernel_regularizer\":null,\n",
        "               \"bias_regularizer\":null,\n",
        "               \"activity_regularizer\":null,\n",
        "               \"kernel_constraint\":null,\n",
        "               \"bias_constraint\":null\n",
        "            }\n",
        "         },\n",
        "         {  \n",
        "            \"class_name\":\"Dense\",\n",
        "            \"config\":{  \n",
        "               \"name\":\"dense_2\",\n",
        "               \"trainable\":true,\n",
        "               \"dtype\":\"float32\",\n",
        "               \"units\":8,\n",
        "               \"activation\":\"relu\",\n",
        "               \"use_bias\":true,\n",
        "               \"kernel_initializer\":{  \n",
        "                  \"class_name\":\"VarianceScaling\",\n",
        "                  \"config\":{  \n",
        "                     \"scale\":1.0,\n",
        "                     \"mode\":\"fan_avg\",\n",
        "                     \"distribution\":\"uniform\",\n",
        "                     \"seed\":null\n",
        "                  }\n",
        "               },\n",
        "               \"bias_initializer\":{  \n",
        "                  \"class_name\":\"Zeros\",\n",
        "                  \"config\":{  \n",
        "\n",
        "                  }\n",
        "               },\n",
        "               \"kernel_regularizer\":null,\n",
        "               \"bias_regularizer\":null,\n",
        "               \"activity_regularizer\":null,\n",
        "               \"kernel_constraint\":null,\n",
        "               \"bias_constraint\":null\n",
        "            }\n",
        "         },\n",
        "         {  \n",
        "            \"class_name\":\"Dense\",\n",
        "            \"config\":{  \n",
        "               \"name\":\"dense_3\",\n",
        "               \"trainable\":true,\n",
        "               \"dtype\":\"float32\",\n",
        "               \"units\":1,\n",
        "               \"activation\":\"sigmoid\",\n",
        "               \"use_bias\":true,\n",
        "               \"kernel_initializer\":{  \n",
        "                  \"class_name\":\"VarianceScaling\",\n",
        "                  \"config\":{  \n",
        "                     \"scale\":1.0,\n",
        "                     \"mode\":\"fan_avg\",\n",
        "                     \"distribution\":\"uniform\",\n",
        "                     \"seed\":null\n",
        "                  }\n",
        "               },\n",
        "               \"bias_initializer\":{  \n",
        "                  \"class_name\":\"Zeros\",\n",
        "                  \"config\":{  \n",
        "\n",
        "                  }\n",
        "               },\n",
        "               \"kernel_regularizer\":null,\n",
        "               \"bias_regularizer\":null,\n",
        "               \"activity_regularizer\":null,\n",
        "               \"kernel_constraint\":null,\n",
        "               \"bias_constraint\":null\n",
        "            }\n",
        "         }\n",
        "      ]\n",
        "   },\n",
        "   \"keras_version\":\"2.2.5\",\n",
        "   \"backend\":\"tensorflow\"\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "Ht4lK9Yboenn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to Save a Keras Model"
      ],
      "metadata": {
        "id": "6475A70g5LTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can save your model by calling the save() function on the model and specifying the filename.\n",
        "\n",
        "The example below demonstrates this by first fitting a model, evaluating it and saving it to the file model.h5."
      ],
      "metadata": {
        "id": "WOSaLDnv5Orp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset saved to single file\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# load pima indians dataset\n",
        "dataset = loadtxt(\"/content/gdrive/My Drive/input_examples/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "# save model and architecture to single file\n",
        "model.save(\"/content/gdrive/My Drive/models/model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3Bfeppbo7gm",
        "outputId": "d1708199-e3de-4846-d29a-c344484d4661"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 78.12%\n",
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example fits the model, summarizes the models performance on the training dataset and saves the model to file."
      ],
      "metadata": {
        "id": "1vQdIQBU5V7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to Load a Keras Model"
      ],
      "metadata": {
        "id": "LZEDY4jqo0Z2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your saved model can then be loaded later by calling the load_model() function and passing the filename. The function returns the model with the same architecture and weights.\n",
        "\n",
        "In this case, we load the model, summarize the architecture and evaluate it on the same dataset to confirm the weights and architecture are the same."
      ],
      "metadata": {
        "id": "kMOkdipKo10O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "\n",
        "# load model\n",
        "model = load_model('/content/gdrive/My Drive/models/model.h5')\n",
        "# summarize model.\n",
        "model.summary()\n",
        "# load dataset\n",
        "dataset = loadtxt(\"/content/gdrive/My Drive/input_examples/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# evaluate the model\n",
        "score = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cpASMFtxJou",
        "outputId": "d013dc65-759c-4c4c-a67d-3983f6d9d190"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_27 (Dense)            (None, 12)                108       \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "accuracy: 78.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example first loads the model, prints a summary of the model architecture then evaluates the loaded model on the same dataset."
      ],
      "metadata": {
        "id": "xcXNrtWl5t8E"
      }
    }
  ]
}