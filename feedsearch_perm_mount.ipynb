{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feedsearch_perm_mount.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEBg9Hx4jeL5uLpYy9HnIC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgamel/learn_n_dev/blob/google_colabs_library_mount/feedsearch_perm_mount.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install feedsearch Permanently on gdrive"
      ],
      "metadata": {
        "id": "-Zzl55CMbdJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Drive"
      ],
      "metadata": {
        "id": "g6wcxJw-cfXh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcYnn-xObbv_",
        "outputId": "bed6fb3f-1010-4231-f044-8a1db583af6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import os, sys \n",
        "#to be able to interact with Google Drive's operating system\n",
        "from google.colab import drive \n",
        "#drive is a module that allows us use Python to interact with google drive\n",
        "drive.mount('/content/gdrive') \n",
        "#mounting google drive allows us to work with its contents\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/gdrive/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)\n",
        "#The last three lines are what changes the path of the file."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### feedsearch\n",
        "\n",
        "Feedsearch is a Python library for searching websites for RSS, Atom, and JSON feeds."
      ],
      "metadata": {
        "id": "ExzXbb6tcwBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --target=$nb_path feedsearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpbB5bVpc7vO",
        "outputId": "27724b96-4d29-4d85-bd15-6d2e71e87d6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting feedsearch\n",
            "  Downloading feedsearch-1.0.12-py35.py36.py37-none-any.whl (18 kB)\n",
            "Collecting Werkzeug\n",
            "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
            "\u001b[K     |████████████████████████████████| 289 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting feedparser\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting click\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
            "Collecting importlib-metadata\n",
            "  Downloading importlib_metadata-4.11.1-py3-none-any.whl (17 kB)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.7.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting typing-extensions>=3.6.4\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 51.3 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 41.7 MB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
            "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
            "Building wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=6fe29eb6da3f9e1a6427e3c867a197cf2e2430243c033d00bd0ed0928fe5bfb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: zipp, typing-extensions, urllib3, soupsieve, sgmllib3k, importlib-metadata, idna, charset-normalizer, certifi, Werkzeug, requests, feedparser, click, beautifulsoup4, feedsearch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.4 which is incompatible.\n",
            "flask 1.1.4 requires Werkzeug<2.0,>=0.15, but you have werkzeug 2.0.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
            "Successfully installed Werkzeug-2.0.3 beautifulsoup4-4.10.0 certifi-2021.10.8 charset-normalizer-2.0.12 click-8.0.4 feedparser-6.0.8 feedsearch-1.0.12 idna-3.3 importlib-metadata-4.11.1 requests-2.27.1 sgmllib3k-1.0.0 soupsieve-2.3.1 typing-extensions-4.1.1 urllib3-1.26.8 zipp-3.7.0\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/bs4 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/feedparser-6.0.8.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/zipp.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/sgmllib3k-1.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/click already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/sgmllib.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/beautifulsoup4-4.10.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/charset_normalizer-2.0.12.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/urllib3-1.26.8.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/typing_extensions-4.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/soupsieve-2.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/importlib_metadata-4.11.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/importlib_metadata already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/zipp-3.7.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/idna-3.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/certifi-2021.10.8.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/requests already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/werkzeug already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/requests-2.27.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/click-8.0.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/soupsieve already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/feedparser already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/idna already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from feedsearch import search"
      ],
      "metadata": {
        "id": "-5w98VhPdN_C"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}